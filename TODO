# -*- org -*-
* DONE Does the sorted-map-by comparator have access to the values as well?
  CLOSED: [2011-08-19 Fri 02:41]
  - CLOSING NOTE [2011-08-19 Fri 02:41] \\
    Apparently not
  #+BEGIN_SRC clojure
    (assert (= "3 2"
               (with-out-str
                 (sorted-map-by
                  (fn [x y] (print (format "%s %s" x y)) true) 2 \a 3 \b))))
  #+END_SRC
* DONE How do maps behave with key-collision?
  CLOSED: [2011-08-19 Fri 02:41]
  - CLOSING NOTE [2011-08-19 Fri 02:41] \\
    Replacement
  #+BEGIN_SRC clojure
    (assert (= {2 4} (assoc (assoc (hash-map) 2 3) 2 4)))
    (assert (= {2 4} (assoc (assoc {} 2 3) 2 4)))
  #+END_SRC
* TODO We are assuming that the dictionary is lower-case.
* DONE Extract some game mechanics into hangman.core.
  CLOSED: [2011-08-18 Thu 03:56]
* TODO Check TODO.pdf into the repository as documentation?
  It goes against checking derivative things in; maybe we can generate
  it for releases. Here's a [[http://stackoverflow.com/questions/1431082/programmatically-add-files-to-a-github-download-page][half-ass discussion]]; 'tis true, though,
  that PDF is a PS-derivative and, as such, is not wholly binary.
* TODO Regex-based GuessingStrategy
  (New pseudo-code syntax, by the way: parenthesized phrases are
  potential optizimations; bracketed phrases are commentary. Also:
  TODOs are full sentences with full stop.)

  #+BEGIN_SRC org
    ,- Create dictionary.
    ,  - Read file and create a list of words.
    ,    - (Order the list by arity, so that pre-filtering is more
    ,      efficient.)
    ,- Initialize filter-strategy on HangmanGame and dictionary.
    ,  - Copy the dictionary.
    ,    - [We're going to have state, unfortunately, since we don't
    ,      control the game loop; or can we use continuations, =yield= or
    ,      coroutines?
    ,  - (Pre-filter dictionary by letter-arity.)
    ,- Next guess
    ,  - Convert =game.getGuessedSoFar= into a suitable regex.
    ,    - Create negative regex: =String.format("[^%s]", new
    ,      String(game.getIncorrectlyGuessedLetters()))=
    ,    - Substitution on =game.getGuessedSoFar= of
    ,      =HangmanGame.MYSTERY_LETTER= for negative regex.
    ,    - Prepend =^=, append =$=.
    ,  - Destructively filter dictionary on regex.
    ,  - If solution is unambiguous, guess word.
    ,    - (Alternatively, some sort of score based on number of possibly
    ,      solutions and number of remaining guesses.)
    ,    - Otherwise, create a sorted map of frequency -> letter (counting
    ,      one letter per word); guess one random sample from the maximally
    ,      frequent letters.
  #+END_SRC
  
  #+BEGIN_SRC clojure	
    (use '[clojure.contrib.io :only (reader)]
         '[clojure.contrib.string :only (replace-str)]
         'hangman.core
         '[clojure.set :only (difference map-invert)])
    
    (import '(com.factual.hangman
              GuessingStrategy
              GuessLetter
              GuessWord
              HangmanGame
              HangmanGame$Status)
            'java.lang.Character)
    
    ;;; Possible optimization: sort by arity.
    (defn make-dictionary [dictionary-file]
      (with-open [dictionary-input (reader dictionary-file)]
        (binding [*in* dictionary-input]
          ;; I would use read-lines here, but I've run into stack
          ;; overflows.
          (loop [word (read-line) words '()]
            (if word
              (recur (read-line) (cons word words))
              words)))))
    
    (defn random-letter []
      (let [letter (+ (rand-int 26) 97)]
        (char letter)))
    
    ;;; This should filter out words containing incorrectly-guessed
    ;;; letters.
    (defn negative-regex [game]
      (let [incorrectly-guessed-letters (.getIncorrectlyGuessedLetters game)]
        (if (empty? incorrectly-guessed-letters)
          "[a-z]"
          (format "[^%s]" (new String (char-array (.getIncorrectlyGuessedLetters game)))))))
    
    (defn make-regex-strategy [dictionary]
      (let [dictionary (atom dictionary)]
        (reify
          GuessingStrategy
          (nextGuess [_ game]
            (let [guessed-so-far (.toLowerCase (.getGuessedSoFar game))
                  negative-regex (negative-regex game)
                  filtering-regex (format "^%s$"(replace-str "-" negative-regex guessed-so-far))
                  filtering-pattern (re-pattern filtering-regex)]
              (swap!
               dictionary
               (fn [dictionary]
                 (filter (fn [word] (re-seq filtering-pattern word)) dictionary)))
              ;; Some heuristic here for guessing.
              (if (= (count @dictionary) 1)
                (new GuessWord (first @dictionary))
                ;; Bidirectional map?
                (let [letter->frequency
                      (loop [words @dictionary
                             letter->frequency (hash-map)]
                        (if words
                          (let [word (first words)
                                letters (distinct word)]
                            ;; Also think about zipmap here.
                            (recur (next words)
                                   (apply merge (cons letter->frequency (map (fn [letter] {letter (+ (get letter->frequency letter 0) 1)}) letters)))))
                          letter->frequency))
                      guessed-letters
                      (map (fn [letter] (Character/toLowerCase letter)) (.getAllGuessedLetters game))
                      letter->frequency
                      (filter (fn [letter-frequency] (not (.contains guessed-letters (first letter-frequency)))) letter->frequency)
                      frequency->letter
                      (into (sorted-map-by >) (map-invert letter->frequency))]
                  (new GuessLetter (second (first frequency->letter))))))))))
    
    ;;; Our algorithm is still deterministic, so we can make these kinds
    ;;; of assertions.
    (assert
     (= (let [dictionary (make-dictionary "words.txt")]
          (reduce (fn [word->score word]
                    (let [game (new HangmanGame word 4)]
                      (assoc word->score word (run game (make-regex-strategy dictionary)))))
                  (sorted-map)
                  '("comaker"
                    "cumulative"
                    "eruptive"
                    "factual"
                    "monadism"
                    "mus"
                    "nagging"
                    "oses"
                    "remembered"
                    "spodumenes"
                    "stereoisomers"
                    "toxics"
                    "trichromats"
                    "triose"
                    "uniformed")))
        {"comaker" 25,
         "cumulative" 8,
         "eruptive" 7,
         "factual" 9,
         "monadism" 10,
         "mus" 25,
         "nagging" 7,
         "oses" 5,
         "remembered" 5,
         "spodumenes" 4,
         "stereoisomers" 3,
         "toxics" 10,
         "trichromats" 5,
         "triose" 7,
         "uniformed" 13}))
    
  #+END_SRC

  At some point, letter guesses don't give me any more information;
  unless I do a diff on the words left. When words are fewer than
  spaces, start guessing words?

  [[http://clojure.org/data_structures#Data Structures-Maps (IPersistentMap)][Maps]]:

  #+BEGIN_QUOTE
  A Map is a collection that maps keys to values. Two different map
  types are provided - hashed and sorted. Hash maps require keys that
  correctly support hashCode and equals. Sorted maps require keys that
  implement Comparable, or an instance of Comparator. Hash maps
  provide faster access (log32N hops) vs (logN hops), but sorted maps
  are, well, sorted. count is O(1). conj expects another (possibly
  single entry) map as the item, and returns a new map which is the
  old map plus the entries from the new, which may overwrite entries
  of the old. conj also accepts a MapEntry or a vector of two items
  (key and value). seq returns a sequence of map entries, which are
  key/value pairs. Sorted map also supports rseq, which returns the
  entries in reverse order. Maps implement IFn, for invoke() of one
  argument (a key) with an optional second argument (a default value),
  i.e. maps are functions of their keys. nil keys and values are ok.

  Related functions
  - Create a new map :: hash-map sorted-map sorted-map-by
  - 'Change' a map :: assoc dissoc select-keys merge merge-with zipmap
  - Examine a map :: get contains? find keys vals map?
  - Examine a map entry :: key val
  #+END_QUOTE

* TODO Regex then trie
# <<regex-then-tries>>
  Let's work with a regex solution that treats the words holistically
  (i.e. as strings); if we can beat regex with some sort of trie:
  great.
* DONE Separate java and clojure dirs under src?
  CLOSED: [2011-08-18 Thu 01:59]
  Could accomplish this with =:source-path= and =:java-source-path=.
* DONE Strings as seqs
  CLOSED: [2011-08-17 Wed 23:51]
  #+BEGIN_SRC clojure
    ;;; Treating strings as seqs of characters.
    (assert
     (= (with-out-str
          (doseq [c "abc"] (println c)))
        "a\nb\nc\n"))
    
    ;;; Convert a string into a seq.
    (assert (= (seq "abc") '(\a \b \c)))
  #+END_SRC
* DONE Implement a trivial GuessingStrategy.
  CLOSED: [2011-08-17 Wed 23:52]
  #+BEGIN_SRC clojure
    (import '(com.factual.hangman
              GuessingStrategy
              GuessLetter
              GuessWord
              HangmanGame
              HangmanGame$Status))
    
    (defn can-keep-guessing?
      ([game] (= (.gameStatus game) HangmanGame$Status/KEEP_GUESSING)))
    
    ;;; We should abstract some of this into hangman.core.
    (defn run
      ([game strategy]
         ;; Can also just wrap this in with-open, since
         ;; assertCanKeepGuessing (in guessLetter and guessWord) will
         ;; throw an exception.
         (while (can-keep-guessing? game)
           (println game)
           (let [guess (.nextGuess strategy game)]
             (.makeGuess guess game)))
         (println game)
         (.currentScore game)))
    
    (defn random-letter []
      (let [letter (+ (rand-int 26) 97)]
        (char letter)))
    
    (defn make-random-strategy []
      (reify
        GuessingStrategy
        (nextGuess [_ game] (new GuessLetter (random-letter)))))
    
    (let [game (new HangmanGame "factual" 4)]
      (assert (= (.currentScore game) 0))
      (assert (= (.gameStatus game) HangmanGame$Status/KEEP_GUESSING))
      (run game (make-random-strategy)))
    
  #+END_SRC
* DONE Read in words, filter on regex.
  CLOSED: [2011-08-17 Wed 16:34]
  #+BEGIN_SRC clojure
    ;;; Roughly 50 msecs.
    (time
     (let [words
           (binding [*in* (reader "words.txt")]
             (loop [word (read-line) words '()]
               (if word
                 (recur (read-line) (cons word words))
                 words)))]
       (filter (partial re-find #"^[^a][^a][e]$") words)))
    
  #+END_SRC
* DONE Read in list of words.
  CLOSED: [2011-08-15 Mon 21:22]
  #+BEGIN_SRC clojure
    (use 'clojure.contrib.io)
    
    ;;; This is about twice as slow: it has to parse the line; it only
    ;;; gathers 53754 words, furthermore, whereas `wc words.txt' gives
    ;;; 173528.
    (time
     (with-in-reader
       "words.txt"
       (loop [word (read *in* false nil) words '()]
         (if word
           (recur (read *in* false nil) (cons word words))
           (count words)))))
    
    ;;; This gives 173529 (including the blank word).
    (time
     (with-open [dictionary (reader "words.txt")]
       (binding [*in* dictionary]
         (loop [word (read-line) words '()]
           (if word
             (recur (read-line) (cons word words))
             (count words))))))
    
    ;;; This is slightly slower than `loop'; gives the right result,
    ;;; though.
    (time (count (reduce (fn [x y] (cons y x)) '() (read-lines "words.txt"))))
    
  #+END_SRC
* DONE Regex
  CLOSED: [2011-08-15 Mon 19:51]
  #+BEGIN_SRC clojure
    (use 'clojure.contrib.str-utils)
    (re-find #"[a-z]+" "harro")
    (re-gsub #"h" "x" "harro")

  #+END_SRC
* DONE Clojure
  CLOSED: [2011-08-17 Wed 23:52]
  On [[http://blog.8thlight.com/articles/2010/12/6/clojure-libs-and-namespaces-require-use-import-and-ns][namespaces]]; let's relegate factual's hangman to
  src/com/factual/hangman, or should we create a separate repo
  containing a jar?

  [[http://p.hagelb.org/import-indent.html][Vectors vs. lists]] in namespaces (fuckers). [[http://www.vineetmanohar.com/2009/11/3-ways-to-run-java-main-from-maven/][Main from maven]], btw.;
  [[http://www.avajava.com/tutorials/lessons/how-do-i-specify-a-main-class-in-the-manifest-of-my-generated-jar-file.html][specifying in MANIFEST.MF]], too.

  On perusing the API:

  =defrecord= like SRFI-9; =comment= like =#;=; but cf =defstruct=;
  =delay=; =deliver=; =disj= like =delete=; also, =dissoc= for maps;
  =doall= for side effects; =doc= reads doc strings, also =^{doc:
  ...}=? cf. =dorun= vs. =doall=; =doseq= appears to be the analogy
  for =for-each=, though; =doall= and =dorun= force the lazy
  evaluation of a sequence, apparently; =dorun= ignores the
  side-effects on the sequence; cf. =unfold=? =doto=: =(doto (new
  java.util.HashMap) (.put "a" 1) (.put "b" 2))=; =do= like =begin=;
  =file-seq=; =fnext= like =cadr=; =for=: lazy list-comprehension;
  =force=; =format= strings (c-style); =gen-class=; =gen-interface=
  (requires compilation?); =gensym=, cool; =get=; =get-in=: "nested
  associative structure": alist? =hash-map=; =identity=; =if-let=;
  =if-not=; =inc=; =interleave= like =zip=; =intern=; =interpose=;
  =into= like =append=? =into-array=; =iterate=: x, (f x), (f (f x));
  =juxt= (ad-hoc, anyone?); =(keep f coll)=: ad-hoc identity filter on
  non-nil; =lazy-cat=; =lazy-seq=; =letfn=; =list*=; =macroexpand=;
  =make-hierarchy= relates to =derive=, =isa?=; =map-indexed=
  (sometimes useful); =memfn=: java method as first-class =fn= ([[http://blog.m.artins.net/clojure-integrating-with-java/][this]]
  is cool: =(map (memfn toUpperCase) ["a" "short" "message"])=);
  =memoize=; =merge= for maps; =meta= for metadata (=^{ ... }=?);
  =next= like =cdr=; =neg?= instead of =negative?= [analogical
  learning]; =nfirst= instead of =cdar=; =nnext= instead of =cddr=,
  etc.; =not-any?=; =not-every?=; =nth= instead of =list-ref=;
  =nthnext= for pairs? =partition=; =pmap= for parallel mapping; =pr=
  like =write= (=write= is intended for =read=, too, I think);
  =pr-str=; =print=, =println=: "human consumption"; =print-str=,
  =println-str=; =printf= (cf. =format=); =prn=: =pr= and =newline=;
  =pvalues=: parallel; =reductions=: intermediate values of
  reductions, too; =reify=: instantiate objects? =remove= also like
  =delete=? lazy; =repeat=; =repeatedly=: like =tabulate=; =replicate=
  like =make-list=; =reset!= like =set!=? =rseq=: reverse =seq=;
  =rsubseq=; =send= for agents; =seq=: seq on the collection; =seque=:
  queued seq; =sequence=: distinct from =seq=; =set=: distinct
  elements; =shuffle=; =some=: =(some #{:fred} coll)= (oh, yeah: sets
  can be used as predicates somehow to test for membership, right?);
  =sort=; =sorted-set=; =str=: to string; =subseq=; =subvec=; =take=;
  =take-last=; =trampoline=: mutual recursion without stack
  consumption; =with-bindings= and =with-bindings*= vs. =binding=
  (former two appear to be "[[http://groups.google.com/group/clojure/browse_thread/thread/c42a24c7b927c2b5][low level]]")?
* DONE Leiningen
  CLOSED: [2011-08-17 Wed 23:52]
  [[http://alexott.net/en/clojure/ClojureLein.html][Pretty good intro]]; workflow:

  #+BEGIN_QUOTE
  - you create a project (=lein new=), define dependencies on external
    libraries and download them with =lein deps= command (you need to
    run it after each change of dependencies);
  - you write your code, periodically running =lein compile=, =lein
    test=, and may be using =lein repl=, =lein swank= or =lein
    nailgun= (depending on your personal preferences) for interactive
    development;
  - if you develop a library, that you plan to use in other projects,
    then you can install it into Maven's local repository with =lein
    install= command, or you can upload it to Clojars (with scp, as
    suggested in documentation, or by using the lein-clojars plugin);
  - if you develop a program for end-user, then you can pack your code
    into package with =lein jar= command (only your code, without
    dependencies), or with =lein uberjar=, with all dependencies
    included into package — it's much easier to distribute such
    packages to end users.
  #+END_QUOTE
* CANCELED Continuations
  CLOSED: [2011-08-18 Thu 01:53]
  Someone did [[https://github.com/swannodette/delimc][delimited continuations]].

  #+BEGIN_SRC clojure
    (use 'delimc.core)
    (assert (= (+ 1 (reset (+ 2 3))) 6))
    (assert (= (+ 1 (reset (+ 2 (shift k 3)))) 4))
    (assert (= (+ 1 (reset (+ 2 (shift k (+ 3 (k 4)))))) 10))
    
  #+END_SRC

  Given the pre-defined interface, though, I'm not sure how we'd fold
  it in: a global continuation, of course, which is mutated by
  =reset!=. Is that principally different than mutating the dictionary state
  of the =GuessingStrategy=?
* CANCELED Graph
  CLOSED: [2011-08-17 Wed 23:53]
  - CLOSING NOTE [2011-08-17 Wed 23:53] \\
    We're not going to go with quasi-Markov-chains now; regex, then
    optimization with [[regex-then-tries][tries]], if necessary.
  Graph based on input words, where the weight is the number of times
  a letter follows another (or precedes?) (this is Markov, isn't it?);
  and an frequency table of letters to seed the guesses.

  Then we do a Dijkstra weighted--shortest-path and greedy
  optimization?

  At some point we need to do a calculation, though, don't we: given
  that we have so many guesses left, etc., what's the cost of guessing
  a word vs. guessing a letter?

  We have neither secretWord nor maxWrongGuesses, though.

  Going with the Dijkstra analogy, we remove edges for wrong guesses;
  each edge represents a potential digram. (Could this be improved
  with n-grams, etc.?)

  1. Get the game;
  2. determine how many letters;
  3. take appropriate words;
  4. build a frequency table for initial guesses (randomizing and
     eliminating ties?);
  5. build a weighted digram graph;
  6. guess correctly: prune the graph (all paths at index {a1, ..., an}
     converge on a) (question is: do we distinguish between letter
     e.g. `a' at positions e.g. 1 and 3? If we permit cycles, the
     links have lower quality; how do we reference index i in the
     graph, though? We do have some starting nodes and perhaps even a
     forest (shit: one graph for each starting letter));
  7. guess incorrectly: prune the graph (no such letter exists).

  We're dealing with a sort of tree here, aren't we, whose leaves are
  words? In other words, given a sequence of correct guesses; it
  should be unambiguous that it signifies a given word. Better yet: we
  should be able to determine the set of signifiable words; we could
  have some heuristic: possible words vs. =maxWrongGuesses=, but I
  don't think we have =maxWrongGuesses=.

  Not true! We have =numWrongGuessesRemaning()= and
  =getMaxWrongGuesses()=. =getSecretWordLength()=: nice! That's what I
  was looking for.

  If =numWrongGuessesRemaning= > $|signifiableWords|$, then we can
  clearly guess all the $\{signifiableWords\}$ one-by-one.

  Thing we're missing is: how do we go from an incompletely determined
  graph to possible words? That's why I suspect we're dealing with,
  not a tree per se, but a graph with terminal vertices; graph if we
  converge on letters: i.e. $\text{c}_1 \to \text{a}_2 \to
  \text{b}_3$, $\text{f}_1 \to \text{a}_2 \to \text{b}_3$; as opposed
  to: $\text{c}_{1_1} \to \text{a}_{2_1} \to \text{b}_{3_1}$,
  $\text{f}_{1_1} \to \text{a}_{2_2} \to \text{b}_{3_2}$. Convergence
  seems to make sense from a space point-of-view, as well as
  determining convergent paths.

  Create a special root node: one artificial graph (graph with
  terminal vertices, not a tree).

  #+BEGIN_SRC makefile :tangle graph.mk :shebang #!/usr/bin/unexpand -t 4
    CLASSPATH := .:$(shell echo lib/*.jar | tr ' ' ':')
    SOURCE := $(wildcard *.java) $(wildcard *.scm)
    OBJECTS := $(patsubst %.java,%.class,$(wildcard *.java)) \
        $(patsubst %.scm,%.scc,$(wildcard *.scm))
    
    .PHONY: test
    
    %.class : %.java
        javac -classpath $(CLASSPATH) $<
    
    %.scc : %.scm
        sisc -e "(compile-file \"$<\" \"$@\")"
    
    test: all
        java -classpath $(CLASSPATH) Hangman words.txt factual
    
    all: $(OBJECTS)
    
  #+END_SRC

  #+BEGIN_SRC java :tangle Hangman.java
    import java.lang.reflect.Array;
    import java.util.Arrays;
    import java.util.Queue;
    import java.io.IOException;
    
    import sisc.interpreter.Interpreter;
    import sisc.interpreter.Context;
    import sisc.interpreter.SchemeCaller;
    import sisc.interpreter.SchemeException;
    import sisc.data.EmptyList;
    import sisc.data.Symbol;
    import sisc.data.Pair;
    import sisc.data.Value;
    import sisc.data.SchemeString;
    import sisc.util.Util;
    import sisc.modules.s2j.JavaObject;
    
    public class Hangman {
        public static final int maxWrongGuesses = 5;
    
        public static int run(HangmanGame game, GuessingStrategy strategy) {
            return 0;
        }
    
        public static void main(final String[] args) throws SchemeException, IOException {
            String dictionary = args[0];
            String[] words = Arrays.copyOfRange(args, 1, args.length);
            for (String word: words) {
                HangmanGame game = new HangmanGame(word, maxWrongGuesses);
                GuessingStrategy strategy = new GraphGuessingStrategy(dictionary, game);
                run(game, strategy);
            }
        }
    }
    
  #+END_SRC

  #+BEGIN_SRC scheme :tangle hangman.scm
    (import s2j)
    
    (define-syntax debug
      (syntax-rules ()
        ((_ x ...)
         (begin
           (write `((x ,x) ...))
           (newline)))))
    
    (define-java-classes
      <guessing-strategy>
      <hangman-game>
      <hangman>)
    
    (define-java-proxy
      (guessing-strategy dictionary game)
      (<guessing-strategy>)
      (define x 2)
      #;
      (define (guessing-strategy dictionary game)
        (set! x 3)
        (debug x))
      (define (next-guess game)
        #;(game get-secret-word-length)
        2))
    
    ;; (debug (java-proxy-class <hangman-game>))
    ;; (debug (java-class-name <hangman-game>)
    ;;        (java-method-name guessing-strategy))
    
    ;; (define-generic-java-methods next-guess)
    ;; (define-generic-java-field-accessors :next-guess)
    
    (define (make-dictionary dictionary)
      (with-input-from-file
          dictionary
        (lambda ()
          (unfold ))))
    
    (define (init strategy dictionary game)
      (debug 2)
      2)
    
    (define (main argv)
      (let ((dictionary (car argv))
            (words (cdr argv)))
        (debug 2 dictionary words)
        ;; (debug (java-new <java.util.linked-hash-set> (->jint 100)))
        ;; (debug (java-new <hangman-game> (->jstring "factual") (->jint 4)))
        (let* ((game (java-new <hangman-game> (->jstring "factual") (->jint 4)))
               (strategy (guessing-strategy dictionary game)))
          strategy)
        #;
        (let ((game (java-new <hangman-game> (->jstring "factual") (->jint 4))))
          (debug game))
    
        ;; (java-new <hangman-game> (->jstring "oeunth") (->jint 5))
        ;; (java-new <hangman-game> "oeuhnt" 5)
        #;
        (with-input-from-file
        dictionary
        (lambda ()
        (let next-word ((word (read)))
        (if (eof-object? word)
        0
        (begin
        (debug word)
        (next-word (read)))))))))
    
  #+END_SRC

  I'm going to assume that the program takes a dictionary file and
  list of words; and that I have to program the glue.

  How is this going to work with initialization, etc.? For clarity,
  should we implement the interface in Java, there to defer to Scheme?

  No, let's do it in Scheme. (Risky.)
  
  We'll define the main run-loop in Java (=run(game, strategy)=); the
  creation of the strategy, however, will defer to Scheme (=new
  GraphStrategy(dictionary)=).

  #+BEGIN_SRC java :tangle GraphGuessingStrategy.java
    import java.io.IOException;
    
    import sisc.interpreter.Interpreter;
    import sisc.interpreter.Context;
    import sisc.interpreter.SchemeCaller;
    import sisc.interpreter.SchemeException;
    import sisc.data.EmptyList;
    import sisc.data.Symbol;
    import sisc.data.Pair;
    import sisc.data.Value;
    import sisc.data.SchemeString;
    import sisc.util.Util;
    import sisc.modules.s2j.JavaObject;
    
    public class GraphGuessingStrategy implements GuessingStrategy {
        
    
        public Guess nextGuess(HangmanGame game) {
            return new Guess() {
                public void makeGuess(HangmanGame game) {
                }
            };
        }
    
        // Let this take, instead, a dictionary-graph.
        public GraphGuessingStrategy(final String dictionary, final HangmanGame game) throws SchemeException {
            Context.execute(new SchemeCaller() {
                    public Object execute(Interpreter interpreter) throws SchemeException {
                        interpreter.loadSourceFiles(new String[] { "hangman.scc" });
                        try {
                            interpreter.eval(Util.proc(interpreter.eval("init")),
                                             new Value[] {
                                                 new JavaObject(this),
                                                 new SchemeString(dictionary),
                                                 new JavaObject(game)
                                             });
                        } catch (Throwable e) {
                            e.printStackTrace();
                        };
                        return true;
                    }
                });
        }
    }
    
  #+END_SRC

  Let's initialize a "strategy-factory" with the dictionary that
  creates a graph for each class of words with letters $2 .. n$. No,
  fuck that: initialize the =GraphGuessingStrategy= with the
  dictionary-graph.

  How do we share the graphs, though? Either it's some sort of opaque
  scheme-object corresponding to, say, a hash-table; or it's some Java
  object (say, =java.util.HashTable=) with which we have to interact
  from Scheme. What are the performance characteristics of both
  scenarios?

  For convenience, I'd rather have Scheme objects to pass around (a
  =Value=, essentially).

  (Oh, check it out: they have a [[http://sisc-scheme.org/manual/javadoc/sisc/modules/hashtable/Hashtable.html][Hashtable]] interface.)

  #+BEGIN_SRC scheme :tangle unfold-file.scm
    (require-library 'sisc/libs/srfi/srfi-1)
    (import srfi-1)
    (import s2j)
    ;; (load "irregex-0.8.1/irregex.scm")
    ;; (require-extension (lib scsh-regexp/scsh-regexp))
    ;; (import scsh-regexp/scsh-regexp)
    
    (define-java-classes
      <java.lang.string>
      <java.util.regex.pattern>)
    
    (define-generic-java-methods
      matches)
    
    (let ((dictionary
           (with-input-from-file
               "words.txt"
             (lambda ()
               (let next-word ((word (read))
                               (dictionary '()))
                 (if (eof-object? word)
                     dictionary
                     (next-word
                      (read)
                      (cons (->jstring word) dictionary))))))))
      #;
      (let ((pattern (->jstring "...")))
        (filter (lambda (word)
                  (->boolean (matches word pattern)))
                dictionary))
      ;; Adds 6 sec.
      #;
      (let ((pattern (->jstring ".......")))
        (filter (lambda (word)
                  (->boolean (matches word pattern)))
                dictionary))
      ;; Adds 6 sec.
      #;
      (let ((pattern (->jstring "...a...")))
        (filter (lambda (word)
                  (->boolean (matches word pattern)))
                dictionary))
      ;; Adds 4 sec; should we bother compiling the regex?
      (let ((pattern (->jstring "...a...")))
        (filter (lambda (word)
                  (->boolean (matches word pattern)))
                (let ((pattern (->jstring ".......")))
                  (filter (lambda (word)
                            (->boolean (matches word pattern)))
                          dictionary))))
      2
      #;
      (for-each (lambda (word)
      'harro
      ;; (irregex-match '(w/nocase ".*") word)
      ;; (matches (->jstring word) (->jstring ".?"))
      #;
      (let ((word (java-new <java.lang.string> (->jstring word))))
      (matches (java-null <java.util.regex.pattern>) word (->jstring ".?"))))
      dictionary))
    
  #+END_SRC

  The issue is: either we have to deal with Scheme strings, Java
  strings or some kind of conversion; the conversion is relatively
  slow (have to do so for e.g. =java.lang.String.match()=); and
  irregex doesn't work (otherwise we could stick with Scheme strings).

  Can we do slow regex for now, and replace it with some e.g. trie
  algo later?

  I just realized that the chaining doesn't matter; we're only dealing
  with frequency, I believe. Could roughly:

  1. Filter the current dictionary based on =getGuessedSoFar()= (this
     could be a string->regex substitution for now and would thus
     carry an O(n * O(regex)) penalty; some sort of e.g. trie-based
     search might get us log-linear).
  2. Is the $|current dictionary| < numWrongGuessesRemaning$? Guess!
  3. Build a frequency list of letters.
  4. Guess one of the most frequent letters; remove it.
  5. Wrong?
     1. Guess again.
  6. Right?
     1. Goto 1.

  Just met Aaron at the Hacker News meetup: drop Scheme, adopt
  Clojure.

  [[http://stackoverflow.com/questions/6339473/python-regex-hangman-algorithm][This]] is subtle, by the way: regexps are susceptible to false
  positives. From the same page:

  #+BEGIN_QUOTE
  As far as determining the next character to guess, you probably
  don't want to select the most frequent character. Instead, you want
  to select the character that comes closest to being in 50% of words,
  meaning you eliminate the most possibilities either way.
  #+END_QUOTE

  Also:

  #+BEGIN_QUOTE
  Your regex should look more like this: '^e[^e][^e][^e][^e]e[^e]$'.
  #+END_QUOTE

  Good call.

  [[http://qs343.pair.com/~monkperl/index.pl?node_id=780414][Frequency and density]]; also: probability that letter is in a given
  position!

  #+BEGIN_QUOTE
  From this, you can easily duplicate my algorithm by determining
  which letter to choose based on which word appears in the most
  candidate words (highest probability of being right) and break ties
  by using the highest overall density.
  #+END_QUOTE

  #+BEGIN_QUOTE
  First, a 1 size fits all algorithm that weighs various different
  pieces of data to produce an overall score. The advantage here is
  that you should be able to tune these weights without touching code
  to produce the best results for a given "dictionary". The second
  approach would be to have multiple algorithms already fine tuned for
  a given set of conditions and dispatch to that algorithm based on
  initial conditions. For instance, it may be ok to take a risk of
  guessing wrong if the remaining wrong guesses is still high or
  perhaps utilize the "simple" algorithm already presented unless the
  probabilities and candidates remaining (if right or wrong) is beyond
  some threshold.
  #+END_QUOTE

  The Markov chains come up again:

  #+BEGIN_QUOTE
  An higher order approach would be to look at probabilities for
  chains of letters. E. g. in English the chance for an 'u' should be
  higher than average after a 'q'.
  #+END_QUOTE

  He's right, actually: looking at mere frequency represents a loss of
  data (`q' followed by `u', for instance, is not handled). Let's
  revisit the Markov idea.

  On the other hand, maybe I was right:

  #+BEGIN_QUOTE
  If 'q' is guessed and is correct, then the next time around, 'u' will
  already jump to the top of the list of letters with the most
  probability to be correct. You don't need to know any special
  knowledge about letter frequency (alone or in chains) to get this benefit.
  #+END_QUOTE

  [[http://qs343.pair.com/~monkperl/index.pl?node_id=779296][Original post]]; this guy is suggesting some kind of binary search:

  #+BEGIN_QUOTE
  At least in your example, a letter never appears in more than half
  of the candidates, so the most frequent letter and the
  closest-to-half-half letter coincide. But imagine if you found out
  that the actual word contained Q. Then for sure the next most common
  letter will be a U; but guessing U and getting it right will not
  give you much new information. Aiming for half-half lets your
  correct and incorrect guesses both contribute information.
  #+END_QUOTE  

  Position:

  #+BEGIN_QUOTE
  My strategy is optimized not to guess wrong. After only 5 guesses (2
  right and 3 wrong) it had narrowed the search space down to exactly
  1 word. This is because I prune by position not just by presence of
  letter so even successful guesses on a popular letter can still
  effectively decrease the search space. Your approach would be
  improved with this strategy as well. I don't think the opportunities
  stop there.
  #+END_QUOTE

  #+BEGIN_QUOTE
  Note that there might be other ways to score each possible
  next-letter guess. Number of non-empty buckets comes to mind as an
  "average case" measure (to be maximized). Again, this is all
  assuming we're minimizing the total number of guesses. That way, all
  of the possible outcomes are (i.e., the guessed letter appears or
  doesn't appear in the word) are treated the same. To minimize the
  number of wrong guesses, you have to treat the "doesn't appear in
  the word" outcome differently and weight things in some better way.
  #+END_QUOTE

  Regex should account for position, shouldn't it?

  #+BEGIN_QUOTE
  Now let's assume we were going with 'eclectic'. There were 9,638
  words in my dictionary with a length of 8. The letter that appeared
  in the most of those words was the letter 'e' at 6,666. Note that I
  didn't count total occurrences of 'e' but only 1 per word. This
  equated to 69%. Now what I set out to do was map the different ways
  the letter 'e' appeared across those 6,666 words. In the word
  'eclectic' it appears in positions 1 and 4 where as in 'envelope' it
  appears in positions 1, 4 and 8. After guessing and seeing which
  positions were filled in, I could even eliminate words with letter
  'e' even if they shared the common position because they didn't
  share all positions. That last part (all positions) was the piece I
  hadn't considered in my previous exercise. So here is the mind
  blowing part. The most common set of positions across the 6,666
  words with the letter 'e' still had less than 1,600 possible
  words. This means that by selecting the letter 'e' (69% chance of
  being right) I will reduce the candidate list from 9,638 to less
  than 1,600 (and probably a lot further). It seemed pointless then to
  come up with some weights for determining letter based on
  probability of being correct and degree to which the candidate list
  is reduced because the "dumb" method was still doing a superb job.

  I do have one last final revision to make. I choose the letter that
  appears in the most candidate words but I don't break
  ties. Currently it is the result of sort. I plan to add total count
  as a secondary tie breaking condition to see if that improves
  results. I should post something later today.
  #+END_QUOTE
* Description
** The Goal

   Write a program that plays the Hangman game. A description of the
   game can be found at http://en.wikipedia.org/wiki/Hangman_(game).

** The Problem

   Your goal is to use a provided API to play Hangman efficiently. You need
   to guess a word using as few guesses as possible, and make no more than
   maxWrongGuesses incorrect guesses. You are writing the letter/word
   guessing strategy.

   We would like you to use the provided Java APIs and to write your solution
   in Java. However, if you don't know Java or are not comfortable with it,
   please feel free to use other reasonably mainstream programming languages
   (C++, Python, Ruby, Scala, etc.). If you do use another language, please
   make sure that your program can accept a dictionary file and a list of
   test words (that are in the dictionary). The output of the program should
   be a score for each test word and the average score across all test words.
   Also, if you don't use Java, please provide build instructions if they are
   not straightforward.

   Your score for a word will be:

   #+BEGIN_QUOTE
   # letter guesses + # number of incorrect word guesses if
   you guessed the word right before making maxWrongGuesses incorrect
   guesses
   #+END_QUOTE

   or

   #+BEGIN_QUOTE
   25 if you lost the game before guessing the word correctly.
   #+END_QUOTE

   You will need to write an implementation of the GuessingStrategy interface
   and some code to use your GuessingStrategy on a HangmanGame instance.

   The pseudocode to run your strategy for a HangmanGame is:

   #+BEGIN_SRC java
     // runs your strategy for the given game, then returns the score
     public int run(HangmanGame game, GuessingStrategy strategy) {
         while (game has not been won or lost) {
             ask the strategy for the next guess apply the next guess to
             the game
         }
         return game.score();
     }
   #+END_SRC

     A trivial strategy might be to guess 'A', then 'B', then 'C', etc. until
     you've guessed every letter in the word (this will work great for "cab"!)
     or you've lost.

     Every word you encounter will be a word from the words.txt file.

** Example

   For example, let's say the word is FACTUAL.

   Here is what a series of calls might look like:

   #+BEGIN_SRC java
     HangmanGame game = new HangmanGame("factual", 4); // secret word is
                                                       // factual, 4 wrong
                                                       // guesses are
                                                       // allowed
     System.out.println(game);
     new GuessLetter('a').makeGuess(game);
     System.out.println(game);
     new GuessWord("natural").makeGuess(game);
     System.out.println(game);
     new GuessLetter('x').makeGuess(game);
     System.out.println(game);
     new GuessLetter('u').makeGuess(game);
     System.out.println(game);
     new GuessLetter('l').makeGuess(game);
     System.out.println(game);
     new GuessWord("factual").makeGuess(game);
     System.out.println(game);
   #+END_SRC

   The output would be:

   #+BEGIN_EXAMPLE
     -------; score=0; status=KEEP_GUESSING
     -A---A-; score=1; status=KEEP_GUESSING
     -A---A-; score=2; status=KEEP_GUESSING
     -A---A-; score=3; status=KEEP_GUESSING
     -A--UA-; score=4; status=KEEP_GUESSING
     -A--UAL; score=5; status=KEEP_GUESSING
     FACTUAL; score=5; status=GAME_WON
   #+END_EXAMPLE

   =game.score()= will be 5 in this case since there were 4 letter
   guesses and 1 incorrect word guess made.

** Sample Data
   As a baseline, here are scores for a reasonably good guessing strategy
   against a set of 15 random words. Your strategy will likely be better for
   some of the words and worse for other words, but the average score/word
   should be in the same ballpark.

   #+BEGIN_QUOTE
   #+BEGIN_EXAMPLE
   COMAKER = 25 (was not able to guess the word before making more than 5
   mistakes)
   CUMULATE = 9
   ERUPTIVE = 5
   FACTUAL = 9
   MONADISM = 8
   MUS = 25 (was not able to guess the word before making more than 5
   mistakes)
   NAGGING = 7
   OSES = 5
   REMEMBERED = 5
   SPODUMENES = 4
   STEREOISOMERS = 2
   TOXICS = 11
   TRICHROMATS = 5
   TRIOSE = 5
   UNIFORMED = 5
   #+END_EXAMPLE
   #+END_QUOTE

** Resources

   You should have been provided with a zip file with source code and
   a dictionary file to get you started. If you were not sent this zip
   file, or you have any questions about the contents, please let us
   know right away.

   The resources contain a dictionary file called words.txt. You can
   assume all words that your program will be tested with come from
   this dictionary file.

** Judging

   Your solution will be graded on the following criteria

     - code quality, readability, and design
     - performance (speed/memory footprint). We are more concerned with
       average time per game, so expensive one-time initialization is okay
       (as long as it's not too egregious)
     - total score for 100 random words, compared to the total score of
       several reference implementations for the same 100 words (max wrong
       guesses is typically set to 5)


